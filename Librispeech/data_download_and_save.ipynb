{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " data download and save",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmontaj/Text-AudioDatasets/blob/main/Librispeech/data_download_and_save.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35WEEAreDkGF"
      },
      "source": [
        "## Downloading and preparing Librispeech dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hw1czforDyDe"
      },
      "source": [
        "##### needed libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1knC1n0aprd",
        "outputId": "afa81ed6-a184-46f2-e8a7-ea5f834be2e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tarfile\n",
        "import os, sys\n",
        "import shutil\n",
        "\n",
        "\n",
        "!pip install wget\n",
        "import wget\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euFVSxbIETG8"
      },
      "source": [
        "##### Downloading and extracting Librispeech "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN-42XODzpXR"
      },
      "source": [
        "def download_librispeech(out, splits):\n",
        "  \"\"\"\n",
        "    Downloading librispeech dataset splits\n",
        "\n",
        "    Arguments:\n",
        "    out -- path to save the dataset on\n",
        "    splits -- list of splits needed to be downloaded. splits are:\n",
        "                    [dev-clean\n",
        "                    dev-other,\n",
        "                    test-clean, \n",
        "                    test-other,\n",
        "                    train-clean-100,\n",
        "                    train-clean-360,\n",
        "                    train-other-500]\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  def _splits_url(split_name):\n",
        "    return \"https://www.openslr.org/resources/12/\"+split_name+\".tar.gz\"\n",
        "\n",
        "  #create this bar_progress method which is invoked automatically from wget\n",
        "  def _bar_progress(current, total, width=80):\n",
        "    progress_message = \"Downloading: %d%% [%d / %d] bytes\" % (current / total * 100, current, total)\n",
        "    # Don't use print() as it will print in new line every time.\n",
        "    sys.stdout.write(\"\\r\" + progress_message)\n",
        "    sys.stdout.flush()\n",
        "  \n",
        "  def _splits_progress(split_name, split_number, splits_count):\n",
        "    progress_message = \"Split: %s [%d / %d]\" % (split_name, split_number, splits_count)\n",
        "    # Don't use print() as it will print in new line every time.\n",
        "    sys.stdout.write(\"\\r\" + progress_message+\"\\n\")\n",
        "    sys.stdout.flush()\n",
        "\n",
        "  split_number = 1\n",
        "  splits_count = len(splits)\n",
        "\n",
        "  for split_name in splits:\n",
        "    _splits_progress(split_name, split_number, splits_count)\n",
        "    wget.download(_splits_url(split_name), out=out, bar=_bar_progress)\n",
        "    split_number+=1"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyqlTt8dsCKt",
        "outputId": "6adb99b7-e07a-42a9-eb39-681d38783900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# download_librispeech(\"\", [\"dev-clean\", \"dev-other\"])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: dev-clean [1 / 2]\n",
            "Downloading: dev-other [2 / 2]\n",
            "Downloading: 100% [314305928 / 314305928] bytes"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-VL_gxc6ohV"
      },
      "source": [
        "def unzip_librispeech(out, extract_path):\n",
        "  \"\"\"\n",
        "  extracting librispeech data\n",
        "\n",
        "  Arguments:\n",
        "  out -- path of the downloaded tar files \n",
        "  extract_path -- path to extract the files on  \n",
        "  \"\"\"\n",
        "  dirs = os.listdir(out)\n",
        "\n",
        "  for i in dirs:\n",
        "    target_name = i.split('.')\n",
        "    name = out +'/'+i\n",
        "    if name.endswith('.tar.gz'):\n",
        "      tar = tarfile.open(i, \"r:gz\")\n",
        "      tar.extractall(extract_path +'/' + target_name[0])\n",
        "      tar.close()\n",
        "  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2tmqlW02LlT"
      },
      "source": [
        "# unzip_librispeech(\".\", \"tst\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtvyPJtxLH_q"
      },
      "source": [
        "##### Organize directories "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzBOOxZGLN1E"
      },
      "source": [
        "def organize_dirs (extract_path, organized_path):\n",
        "  \"\"\"\n",
        "  extracting librispeech data\n",
        "\n",
        "  Arguments:\n",
        "  extract_path -- path to extract the files on  \n",
        "  organized_path -- path to organize the files in  \n",
        "  \"\"\"\n",
        "  dirs = os.listdir(extract_path)\n",
        "  for dir in dirs:\n",
        "    shutil.move(extract_path+ '/'+ dir+ '/' + 'LibriSpeech/'+ dir , organized_path)\n",
        "  \n",
        "  common_files_path = extract_path + '/' + dirs[0]+'/' + \"LibriSpeech\"\n",
        "  dirs = os.listdir( common_files_path )\n",
        "\n",
        "  for f in dirs:\n",
        "    shutil.move(common_files_path+'/'+ f , organized_path)\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCfpoqWaLwfK",
        "outputId": "200ffc6d-4086-4374-e9f3-8813506a5c0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# organize_dirs (\"./tst\", \"./tst2\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev-clean\n",
            "dev-other\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS0wI8yX5MoN"
      },
      "source": [
        "def _remove(dir_path):\n",
        "  \"\"\"\n",
        "  extracting librispeech data\n",
        "\n",
        "  Arguments:\n",
        "  dir_path -- path to dirctory or file to remove  \n",
        "  \"\"\"\n",
        "  os.system('rm -R %s' %dir_path)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UQdPZNY61Ib"
      },
      "source": [
        "def download_and_extract(out, splits, extract_path, organized_path, clean_organized_path=False):\n",
        "  download_librispeech(out, splits)\n",
        "  unzip_librispeech(out, extract_path)\n",
        "  if clean_organized_path:\n",
        "    _remove(organized_path)\n",
        "  organize_dirs (extract_path, organized_path)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzWtHWnSa_XB"
      },
      "source": [
        "def load_metadata(data_path):\n",
        "  \"\"\"\n",
        "  extracting librispeech data\n",
        "\n",
        "  Arguments:\n",
        "  data_path -- path to dataset\n",
        "  \"\"\"\n",
        "\n",
        "  # edits to be done in the data before loading it\n",
        "  # edit line 45 remove || \n",
        "  # edit ;id to be id \n",
        "  #-----------------------------------------\n",
        "  # use sep | and skip first 11 rows \n",
        "\n",
        "  speakers = pd.read_csv(data_path+\"/\"+'SPEAKERS.TXT', sep=\"|\", skiprows=11)\n",
        "  return speakers"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uosOfDuE9Ai7",
        "outputId": "a31a24a8-1cea-46ac-9149-0e72b162a689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "load_metadata(\"./tst2\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>SEX</th>\n",
              "      <th>SUBSET</th>\n",
              "      <th>MINUTES</th>\n",
              "      <th>NAME</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14</td>\n",
              "      <td>F</td>\n",
              "      <td>train-clean-360</td>\n",
              "      <td>25.03</td>\n",
              "      <td>Kristin LeMoine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>F</td>\n",
              "      <td>train-clean-360</td>\n",
              "      <td>25.11</td>\n",
              "      <td>Alys AtteWater</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17</td>\n",
              "      <td>M</td>\n",
              "      <td>train-clean-360</td>\n",
              "      <td>25.04</td>\n",
              "      <td>Gord Mackenzie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>19</td>\n",
              "      <td>F</td>\n",
              "      <td>train-clean-100</td>\n",
              "      <td>25.19</td>\n",
              "      <td>Kara Shallenberg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20</td>\n",
              "      <td>F</td>\n",
              "      <td>train-other-500</td>\n",
              "      <td>30.07</td>\n",
              "      <td>Gesine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2479</th>\n",
              "      <td>8975</td>\n",
              "      <td>F</td>\n",
              "      <td>train-clean-100</td>\n",
              "      <td>25.11</td>\n",
              "      <td>Daisy Flaim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2480</th>\n",
              "      <td>9000</td>\n",
              "      <td>M</td>\n",
              "      <td>train-other-500</td>\n",
              "      <td>27.26</td>\n",
              "      <td>Ramon Escamilla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2481</th>\n",
              "      <td>9022</td>\n",
              "      <td>F</td>\n",
              "      <td>train-clean-360</td>\n",
              "      <td>25.17</td>\n",
              "      <td>Claire M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2482</th>\n",
              "      <td>9023</td>\n",
              "      <td>F</td>\n",
              "      <td>train-clean-360</td>\n",
              "      <td>25.19</td>\n",
              "      <td>P. J. Morgan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2483</th>\n",
              "      <td>9026</td>\n",
              "      <td>F</td>\n",
              "      <td>train-clean-360</td>\n",
              "      <td>21.75</td>\n",
              "      <td>Tammy Porter</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2484 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      ID    SEX   SUBSET             MINUTES               NAME\n",
              "0       14   F    train-clean-360      25.03    Kristin LeMoine\n",
              "1       16   F    train-clean-360      25.11     Alys AtteWater\n",
              "2       17   M    train-clean-360      25.04     Gord Mackenzie\n",
              "3       19   F    train-clean-100      25.19   Kara Shallenberg\n",
              "4       20   F    train-other-500      30.07             Gesine\n",
              "...    ...  ...                 ...      ...                ...\n",
              "2479  8975   F    train-clean-100      25.11        Daisy Flaim\n",
              "2480  9000   M    train-other-500      27.26    Ramon Escamilla\n",
              "2481  9022   F    train-clean-360      25.17           Claire M\n",
              "2482  9023   F    train-clean-360      25.19       P. J. Morgan\n",
              "2483  9026   F    train-clean-360      21.75       Tammy Porter\n",
              "\n",
              "[2484 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHBxE8sU9Gm_"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(filename,names=['code'])\n",
        "df[['code','name_of_code']] = df[\"code\"].str.split(\" \", 1, expand=True)\n",
        "df[\"name_of_code\"] = df[\"name_of_code\"].str.strip(\"-\")\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}